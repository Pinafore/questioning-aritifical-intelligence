{
    "introduction": "Since this is a book about question answering, I should try to answer some questions to start things out.  I'm going to try to answer: ``what's this book about'', ``who am I'', and ``who can use this book''.",
    "turing": "In the 1950s, Alan Turing proposed a parlor game that would come to define the artificial intelligence: could a wiley interrogator discern whom they were talking to just through posing clever questions.  The eponymous Turing Test is the most durable (but contentious) definition of what an intelligent computer is, and this chapter reviews how it shaped the development of artificial intelligence.",
    "epic": "Despite its central importance to \\abr{ai}, asking and answering questions is new---it stretches back into our collective unconcious. Riddles and trivia have persisted for millenia not just because they're entertaining.  Indeed, being able to ask and answer questions is close to godliness.  From the Sphynx to Gestumblindi, this chapter examines how myths from several cultures connect answering questions to forming identity, unlocking the secrets of the universe, and gaining intelligence.  And connecting this to nascent ``superhuman'' \\abr{ai}.  Previously published as \\citet{Rodriguez-21:paradigms}.",
     "civilization": "Corruption and nepotism have been the downfall of multiple civilizations, but the administration of carefully formed questions saved the United States and China from sucumbing to these destructive forces.  From the reforms of Wu Zetian to the Pendelton Act, this chapter examines how information and competence---measured by questions asked in an exam---created meritocracy and social mobility.  The legacy of these exams built an understanding of what it means to write a ``fair'' and ``useful'' question, and brought about massive social change, allowing egalitarian and professional governments to bring order to continent-spanning civilizations.",
    "ir": ["Information retrieval is the foundation of multi-billion dollar web companies from Baidu to Yahoo!  But none of these companies would exist without the ideas of reusable test collections and term-based queries, which came about because of a few crazy experiments that happened in a small UK University in Cranfield.  This chapter lays out the history of this methodology (which has become known as the Cranfield paradigm) and how it can answer questions.",
	   [["sec:ir:gofai-qa", "Old-Fashioned \\abr{ai}"]]
	   ],
    "manchester": ["While computer scientists were getting their feet wet answering questions in the wake of World War II, trivia enthusiasts were perfecting how to ask the perfect question.  This chapter outlines the conventions and processes of the highest form of question answering---in the biased opinion of the author---and argues for why many of these standards could be a part of creating data for computer question answering.  Previously published as \\citet{boyd-graber-20}.",
		   [["sec:manchester:qb", "Quiz Bowl"]]
		   ],
    "watson": "It's been nearly a decade since IBM Watson crushed two puny humans on Jeopardy!  Some people took that to mean that computers were definitively better than humans at trivia.  But that isn't the complete answer---this chapter, inspired by Jeopardy!'s gimmick of responding to answers to questions, questions some of the ``answers'' that emerged from IBM's tour de force.",
    "datasets_found": ["The cliche is that data are the new oil, powering \\abr{ai}.  Fortunately, because humans naturally ask questions, there are many datasets that we can find 'for free'.  However, these datasets still come at a cost: many of these datasets have inherent problems (e.g., ambiguities and false presuppositions) or oddities (only talking about American men) that make them difficult to use for question answering.  This chapter discusses these datasets that have formed the foundation of much of modern \\abr{ai}.",
			 [["sec:nq:problems", "Natural Questions Five Years Later"],
			  ["sec:nq:iid", "Should QA be IID?"]]
			], 
    "formats": ["How do you ask a question: is it text, a picture, or a conversation?  This chapter reviews the different forms question answering can take and what complexities that can introduce.",
		[["sec:formats:multimodal", "Multimodal Questions"]]
		],
     "datasets_constructed": "If you can't find the data you need, build it yourself.  But this is not always a perfect solution.  This chapter discusses the datasets that people have built and the new problems that this can create.",
     "methods_kb": "The first question answering approaches were about extracting specific nuggets from a database using natural language.  These first approaches are not just historically important but are still influencing many question answering approaches of today.  This chapter reviews how we can turn natural language queries into actionable queries in databases.",
     "methods_mr": "However, putting information in a database is difficult and time-consuming\\dots not all information is in a database (indeed, some information defies strict database schemas).  Thus, we need to teach computers how to read.  This chapter reviews the process of ``machine reading'', where computers find information in a large text corpus and then extracts the answer from it.",
     "methods_deep_retrieval": "As deep learning became practical, the field has moved from representing text with discrete words to continuous vectors.  This is also the case for question answering.  This chapter reviews how these representations can help us find relevant answers to questions.",
    "methods_generation": "The deep learning revolution not just helps us find answers but to generate them.  This chapter talks about the promise and peril of these approaches: how we can synthesize much richer information, make stuff up, encourage these agents to align to our wishes, and how it's hard to tell if an answer is any good.",
    "leaderboards": "How do we know how smart a machine is?  Like a human, we typically give it a test; the difference is that tests for computers are called `leaderboards'. This chapter talks about the pros and cons of leaderboards and how some of the methods used to analyze human standardized tests can help us understand the strengths and weaknesses of not just computer question answering specifically but \\abr{ai} generally.  This also marks the reappearance of item response theory, which can help make deciding the smartest computer more efficient.  Previously published as \\citet{Rodriguez-21:leaderboards}.",
    "datasets_adversarial": ["If existing datasets and game show appearances aren't enough to tell whether humans or computers are better at answering questions, what can we do?  While there is an argument for focusing on natural data, modern language models are changing not just what is possible computationally but changing the language itself.  Thus, we need to select examples specifically to challenge computers. These examples are called \\emph{adversarial examples}, and this chapter presents how to gather them and how they can reveal the strengths and weaknesses of computer question answering.", [["sec:adversarial:cooperation", "Humans and Computers Working Together can Answer Questions Better"]]],
     "gameshow": "The year is 2025, and there's a new gameshow that not only showcases the most advanced \\abr{ai} available but also keeps the public informed about the limitations and struggles of current technology.  This chapter outlines the ten seasons of the show and how it tracks the development of machine intelligence, leading to passing Turing Test.",
    "sci_fi": "While the book began with how question answering in myth helped the ancients grapple with a changing and uncertain world, today's fictions represent our contemporary attempts to understand the advent of intelligent computers.  This chapter reviews human--computer question answering in 2001, Star Trek, The Terminator, Blade Runner, Futurama, and what these depictions reveal about both human conceptions of artificial intelligence and how it might shape future deployments of question answering.",
      "fear_of_a_bot_planet": "Beyond the imagining of science fiction, what are the actual downsides to the widespread availability and deployment of `intelligent' \\abr{ai}?  This chapter talks about \\abr{ai}'s ability to amplify existing negative \\emph{human} tendencies in responding to questions and how---while dangerous and worthy of mitigation---don't demand us to halt the development of modern \\abr{ai}."
} 
