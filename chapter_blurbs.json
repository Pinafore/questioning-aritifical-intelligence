{
    "introduction": "Since this is a book about question answering, I should try to answer some questions to start things out.  I'm going to try to answer: ``what's this book about'', ``who am I'', and ``who can use this book''.",
    "turing": "In the 1950s, Alan Turing proposed a parlor game that would come to define the goal of creating human-like artificial intelligence: could a wiley interrogator discern whom they were talking to just through posing clever questions.  Alan Turing's eponymous Turing Test is the most durable (but contentious) definition of what it means for a computer to be intelligent.  This chapter reviews how Alan Turing's postwar thought experiment of humans asking computers questions shaped the development of artificial intelligence.",
    "epic": "Despite its central importance to \\abr{ai}, asking and answering questions is not a recent development---it stretches back into our collective unconcious. Riddles and trivia have been with us for millenia not just because they're entertaining; it's more than that.  The ability to ask and answer questions is       close to godliness.  Through the lens of the Riddle of the       Sphynx and Gestumblindi, this chapter examines what makes a good question in the eyes of the Gods.  Myths from several cultures connect the process of forming and answering critical questions to the process of forming identity, unlocking the secrets of the universe, and gaining intelligence.",
     "civilization": "Corruption and nepotism have been the downfall of multiple civilizations, but the administration of carefully formed questions saved the United States and China from sucumbing to these destructive forces.  Civil service exams broke the corruption and randomness of patronage and familial bonds.  By examining the reforms of Wu Zetian and the Pendelton Act, this chapter examines how information and competence---measured by questions asked in an exam---created meritocracy and social mobility.  The legacy of these exams built an understanding of what it means to write a ``fair'' and ``useful'' question, and brought about massive social change, allowing egalitarian and professional governments to bring order to continent-spanning civilizations.",
     "ir": "Information retrieval is the foundation of many multi-billion dollar web companies from Baidu in China to Yandex in Russia to Google and Yahoo! in the US.  But none of these companies would exist without the ideas of reusable test collections and term-based queries, which came about because of a few crazy experiments that happened in a small UK University in Cranfield.  This chapter lays out the history of this methodology (which has become known as the Cranfield paradigm) and how it was used to answer questions.",
     "qb": "While computer scientists were getting their feet wet answering questions, during the same period trivia enthusiasts were perfecting how to ask the perfect question.  This chapter outlines the conventions and processes of the highest form of question answering---in the biased but informed opinion of the author---variously called University Challenge, College Bowl, or Quiz Bowl and argues for why many of these processing could be a part of creating data for computer question answering.",
     "watson": "It's been nearly a decade since IBM Watson crushed two puny humans on Jeopardy!  Some people took that to mean that computers were definitively better than humans at trivia.  But that isn't the complete answer---this chapter, inspired by Jeopardy!'s gimmick of responding to answers to questions, questions some of the ``answers'' that emerged from IBM's tour de force.",
    "datasets_found": "The cliche is that data are the new oil, powering \\abr{ai}.  Fortunately, because humans naturally ask questions, there are many datasets that we can find 'for free'.  However, these datasets still come at a cost: many of these datasets have inherent problems (e.g., ambiguities and false presuppositions) or oddities (only talking about American men) that make them difficult to use for question answering.",
    "formats": "How do you ask a question: is it text, a picture, or a conversation?  This chapter reviews the different forms question answering can take and what complexities that can introduce.",
     "datasets_constructed": "If you can't find the data you need, build it yourself.  But this is not always a perfect solution.  This chapter discusses the datasets that people have built and the problems that this can create.",
     "methods_kb": "The first question answering approaches were about extracting specific nuggets from a database using natural language.  These first approaches are not just historically important but are still influencing many question answering approaches of today.  This chapter reviews how we can turn natural language queries into actionable queries in databases.",
     "methods_mr": "However, putting information in a database is difficult and time-consuming\\dots not all information is in a database (indeed, some information defies strict database schemas).  Thus, we need to teach computers how to read.  This chapter reviews the process of ``machine reading'', where computers find information in a large text corpus and then extracts the answer from it.",
     "methods_deep_retrieval": "As deep learning became practical, the field has moved from representing text with discrete words to continuous vectors.  This is also the case for question answering.  This chapter reviews how these representations can help us find relevant answers to questions.",
    "methods_generation": "The deep learning revolution not just helps us find answers but to generate them.  This chapter talks about the promise and peril of these approaches: how we can synthesize much richer information, make stuff up, encourage these agents to bow to our wishes, and how it's hard to tell if an answer is any good.",
    "leaderboards": "How do we know how smart a machine is?  Like a human, we typically give it a test; the difference is that tests for computers are called `leaderboards'. This chapter talks about the pros and cons of leaderboards and how some of the methods used to analyze human standardized tests can help us understand the strengths and weaknesses of computer question answering, and how human trivia tournaments can help make deciding the smartest computer more efficient.",
     "datasets_adversarial": "If existing datasets and game show appearances aren't enough to tell whether humans or computers are better at answering questions, what can we do?  While there is an argument for focusing on natural data, modern language models are changing not just what is possible computationally but changing the language itself.  Thus, we need to select examples specifically to challenge computers. These examples are called \\emph{adversarial examples}, and this chapter presents how to gather them and how they can reveal the strengths and weaknesses of computer question answering.",
     "game_show": "The year is 2025, and there's a new gameshow that not only showcases the most advanced \\abr{ai} available but also keeps the public informed about the limitations and struggles of current technology.  This chapter outlines the ten seasons of the show and how it tracks the development of machine intelligence, leading to the Turing Test.",
    "sci_fi": "From humans and dieties posing each other questions to humans and computers facing off in the Turing test, these face-offs have also become a staple of science fiction.  This chapter reviews human--computer question answering in 2001, Star Trek, The Terminator, Blade Runner, Futurama, and novels and what these depictions reveal about both human conceptions of artificial intelligence and how it might shape future deployments of question answering.",
      "fear_of_a_bot_planet": "Beyond the imagining of science fiction, what are the actual downsides to the widespread availability and deployment of `intelligent' \\abr{ai}?  This chapter talks about \\abr{ai}'s ability to amplify existing negative \\emph{human} tendencies and how---while dangerous and worthy of mitigation---don't demand us to halt the development of modern \\abr{ai}."
} 
