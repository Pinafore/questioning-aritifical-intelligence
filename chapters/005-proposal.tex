
\clearpage

\paragraph{Proposed Title and Subtitle} \vspace{3cm}

{\bf Questioning Artificial Intelligence}: How the Art of Asking Questions Defines AI and Helps Navigate an Uncertain Future

\vspace{3cm}

\abr{ai} has been defined by asking questions even before it was ``a
thing'': Alan Turing designed a question answering proceduring to
determine if machine is intelligent.
%
In the years since, \abr{ai} has continued to be defined by questions:
answering questions on \jeopardy{} and on our phones.

This book looks at not just the \emph{how} of computers answers
questions but also \emph{why} answering questions is so important
for \abr{ai}.
%
Answering that ``why'' questions requires us to go back to
mythological, civil service exams, and game shows and connect them
to \abr{ai} question answering.

\paragraph{Full Description}

We call someone smart if they can answer questions: the pass a test, win
on \jeopardyp{}, or offer a witty retort in a debate.
%
This is not just a recent phenomenon.
%
Question answering is deeply embedded in
our culture:
%
in myth \OE{}dipus answered the riddle of the sphynx;
%
getting into a school depends on passing a standardized test;
%
good governance depends on civil service exams;
%
a trivia subculture has grown around answering all manner of questions.

What is new is that computers are now getting into the game of answering
questions.
%
From \abr{ibm} Watson on \jeopardy{} to Siri and Alexa in every home, the ability of
computers to answer is a common yardstick of how smart computers are.

This book is not a book about how to build \abr{ai} systems or how use natural
language processing to extract answers from Wikipedia.
%
Nor is it an insider's guide to the world of high-stakes educational testing,
trivia games, or licensing exams.
%
We'll only introduce the reader to all of these interesting subcultures
from the trivial to the technical.  

Unlike highly focused books on those individual domains, the goal of this book is to
draw \emph{connections} between the two worlds of human and computer
question answering, show how human expectations of \abr{qa} have
shaped \abr{ai} thus far, how there's still more to learn from
human \abr{qa}, and how a more mature \abr{ai} landscape may change
how humans answer questions.

To be transparent, this book has an agenda: we can better understand
artificial intelligence by looking at its ability to answer questions
through this historical lens.
%
If we want to call a computer smart---indeed, smarter than a
human---we should make sure the competition is fair.
%
Moreover, writing and asking questions is an art that has been refined
over decades.

Part of the story I want to tell is how we got here.
%
And why little things like the decisions made at a tiny British
library in Bedfordshire fifty years ago have locked the artificial
intelligence community into a particular way of evaluating whether a
computer is smart.
%
These historical decisions have shaped the systems that we have today;
as a consequence, we are stuck with the crappy answers from our
smartphone.

But it didn't have to be this way!
%
The very definition of computing and artificial intelligence was based a
thought experiment that is closer to how computers and humans should interact
with each other.
%
However, that definition---from a boffin in Manchester called Alan
Turing---was too fanciful to really be implemented in the lab in the
twentieth century.
%
I'll argue that we could do something closer to Alan Turing's vision,
and you, the reader, can judge whether it's (still) too fanciful.

This is not just a narrow question for those building question
answering systems.
%
I think that the way we interact with our smartphones and computers
will define the future of human--computer interaction and
thus the shape of the modern, \abr{ai}-infused economy.

\paragraph{How the Book is Structured}

We set the stage in two British Universities in the mid-twentieth
century and show how two researchers set the stage for rival paradigms
of artificial intelligence in the twentith century.
%
Having set the stage of this rivalry, we then trace the roots of these
two paradigms: civil service exams vs. library information desks, game
shows vs. standards bodies vs. standardized tests.

Having covered the history, the book turns to the present and the
hotly debated question of whether today's \abr{ai} is closer to Clever
Hans or to \abr{hal}.
%
We approach this central question through the
influence of the Cranfield and Manchester paradigms in three vignettes.
%
These stories detail three modern \abr{ai} triumphs where companies
have used question answering to turbocharge their \abr{ai}
research: \abr{ibm}'s Watson, Google's Natural Questions (and the connection to Muppets), and
Facebook's Dynabench leaderboard.
%
But rather than simply recount what these companies did, the
perspective of the first section allows us to critically examine the
important questions of whether the comparison between human and
machines is fair and how much the technical advantages reshaped the
field.

Finally, we turn our eyes to the future of \abr{ai} and \abr{qa}.
%
How can we take lessons from trivia games and standardized tests to know
when we've made progress in comparing human and machine intelligence
and to prod research in the right direction.

\begin{comment}
\begin{enumerate}
        \item Question Answering Past

        \begin{enumerate*}
                \item {\bf Epic Questions}: Riddles and trivia have been with us for
                millenia.  One reason is that they're entertaining.  But it's
                more than that: the ability to ask and answer questions is
                close to godliness.  Through the lens of the Riddle of the
                Sphynx and Gestumblindi, this chapter examines what makes a
                good question in the eyes of the Gods.

              \item {\bf How Exams Saved Civilization}: Civil service
                exams broke the corruption and randomness of patronage
                and familial bonds.  By examining the reforms of Wu
                Zetian and the Pendelton Act, this chapter examines
                how information and competence---measured by questions
                asked in an exam---created meritocracy and social
                mobility.  The legacy of these exams built an
                understanding of what it means to write a ``fair'' and
                ``useful'' question, which has unfortunately been
                forgotten by \abr{ai} researchers.

        \end{enumerate*}

        \item Question Answering Present

        \begin{enumerate*}

        \item {\bf The Turing Test: A Game Show Pitch that Defined Artificial Intelligence}: Alan Turing's eponymous Turing
          Test is the most durable (but contentious) definition of
          what it means for a computer to be intelligent.  This
          chapter reviews how Alan Turing's postwar thought experiment
          of humans asking computers questions shaped the development
          of artificial intelligence.

        \item {\bf The Creation of Trivia's Gold Standard}: Just as
          Alan Turing's wartime exploits shaped \abr{ai}, this chapter
          charts the course of how a Canadian soldier created a
          revolution in how humans play trivia games (but these
          insights are ignored by the computer community).

        \item {\bf What Makes a Good Question}:\footnote{Published as a
        position piece at the Association of Computational Linguistics 2020.}
        Contrasting with the previous chapter, this chapter describes the best
        practices of human question answering---non-ambiguous, discriminative,
        and fair---and how these best practices grew out of decades of
        refinement.

      \item {\bf Watson on Jeopardy!: Unquestioned Answers from IBM's
          tour de force}: The most memorable computer to answer
        questions caused the public to think that question answering
        had been ``solved'', but that's not true.  This chapter breaks
        down why despite the hype and victory Watson's victory doesn't
        tell us that much about how well computers can answer
        questions.

        \item {\bf How Google, Alexa, and Siri Answer Questions Today}:
        This chapter reviews how computers answer questions: learning from
        example datasets and then recreate those examples from those datasets.
        This chapter critically examines how computers answer questions and
        how this can make computers seem smarter than they are.
        
        \item {\bf Cranfield vs. Manchester}:\footnote{Submitted as a short
        position piece to Empirical Methods in Natural Language Processing
        2021.} At a 1960s meeting in Cranfield, the computer science community
        embarked on a paradigm that downplayed the user of experts in defining
        systems.  This legacy, a shift from Alan Turing, still defines
        question answering today.

        \item {\bf What Leaderboards have Done to AI Research (and how
          trivia can save it)}: Computers compete on
        leaderboards, while humans compete at tournaments.  The latter has
        been optimized over decades to efficiently select the best human
        competitor, while leaderboards have not taken advantage of the tips
        and tricks that make tournaments for humans fun and informative.

        \end{enumerate*}

        \item Question Answering Future

        \begin{enumerate*}
        \item {\bf Science Fiction Question Answering}: Science fiction is the
        standard mode of predicting how humans and computers will interact in
        the future.  From Hal's questions in \textit{2001} to the Voigt-Kampff
        test in \textit{Blade Runner}, this chapter reflects on how plausible
        and what warnings science fiction offers for question answering.

        \item {\bf Human--Computer Centaurs}: This chapter looks at
        another \abr{ai} victory---chess---and how computers evolved into
        collaborators of humans rather than competitors.  How should computers
        and humans work together to answer hard questions?  The answer (and
        how we build \abr{ai} systems) will determine the future of the
        economy.

        \item {\bf Computer Game Shows of the Future}: Finally, we bring
        together two of the themes of the book: computers answering questions
        and game shows.  How could we use the gimick of the game show format
        to shape \abr{ai} into what would best serve society and help inform the
        public about the true state of \abr{ai} research?

        \end{enumerate*}

\end{enumerate}
\end{comment}


\paragraph{Author Information}

Jordan Boyd-Graber is an associate professor at the University of Maryland.
He recieved a PhD from Princeton in 2010 in Computer Science and a bachelor's
degree in History from the California Institute of Technology.
%
His work has been recognized with ``best of'' awards at Intelligent User
Interfaces, Neural Information Processing Systems, the North American
Association for Computational Linguistics, and the Conference on Natural
Language Learning.
%
He also recieved a National Science Foundation \abr{career} award and the 2015
Karen Sp\"ark Jones Award.
%
He has published over a hundred peer-reviewed publications on interactive
machine learning, question answering, and exploring document collections.
%
With David Mimno and Yuening Hu, he wrote \emph{Applications of Topic Models}.

In addition to his academic research, Boyd-Graber is also active in the trivia
community: he founded the University of Colorado Quiz Bowl team, revived the
Princeton Graduate College Pub Quiz, coaches the national champion University
of Maryland Academic Quiz Team, and has lost on \jeopardyp{} (his
students are particularly fond of mocking his poor performance on the
video game category).

\paragraph{Book Audience}

The book is intended either for the general public to learn about humand and computer
question answering or for machine learning researchers to learn
how \emph{human} question answering can improve their computer question
answering systems.

Possible classes where it could be used:
\begin{itemize}
        \item A freshman seminar introducing students to \abr{ai}.
        \item A graduate seminar in information seeking or evaluation.
        \item A companion to technical papers in a graduate computer science course.
\end{itemize}

\paragraph{Comparable Books}

\begin{itemize}
        \item Ken Jennings.  \textit{Braniac: Adventures in the Curious,
        Competitive, Compulsive World of Trivia Buffs}.  Villard, 2007.

        \item Mark T. Maybury.  \textit{New Directions in Question
        Answering}.  AAAI Press, 2004.

        \item Navin Sabharwal and Amit Agrawal.  \textit{Hands-on Question
        Answering Systems with BERT}.  A Press, 2021.
\end{itemize}


\paragraph{Additional Information and Specifications}

Estimated book contents:
\begin{itemize}
  \item 150 Single-spaced pages
  \item Two dozen diagrams / illustrations
  \item Draft to reviewers December 31, 2022, revisions/edits until
    June 31, 2021
\end{itemize}

Three chapters were published as position papers.  If accepted, the
chapters will be substantially revised to flow well with and
complement other chapters.

Sample chapter to follow.
