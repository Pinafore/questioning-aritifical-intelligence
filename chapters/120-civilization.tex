I mostly talk about computers answering questions.  And I also talk about silly trivia games.  As a result, you may think that question answering is unimportant, but it’s often deadly serious.  Today, I’m talking about how question answering is the bedrock of civilization: humans answering questions is more common and more important than computer question answering.  My goal is to remind you how important these question answering applications are and to see connections to how we can learn from milenia of human question answering.

Another pillar of civilization is making sure that those who work for society (in other words, civil servants) are competent.  As governments became larger and had to rule an entire continent, countries had to develop civil service examinations.  Many countries did this, including the US, whose Pendelton act ended an era of political patronage. 

But I’d rather talk about the granddaddy of civil service exams, ke1ju3, which for 1300 years determined who became part of the intelligentsia of Imperial China.   
It encouraged social mobility by getting smart people good jobs and it encouraged good governance by making sure that important jobs were done by smart people.  And this is important when you have a diverse, massive, empire that is run by a centralized bureaucracy.  Again, this shows that civilization is not possible without effective systems of question answering.

This system worked well for so long because it was built on a foundation of fairness.  The organizers thought about the potential for bias: the exams were transcribed so that bad handwriting wouldn’t be judged against an applicant, children of current members of the imperial court had to submit their exams in their home province, etc.  

Now, it wasn’t perfect, Most notably its quotas led to imbalances between regions.  But it was important enough that recent scholarship has suggested that its abolition after the Russo-Japanese war and a turn to ``Western-style'' education on the Prussian model that turns out good soldiers, helped hasten the end of the Q\-ing dynasty.

As  Shiuon Chu argues, it’s not just that you have a test to make sure that the smartest people are doing important jobs in society.  Part of the process is also to explain why people got the questions wrong!  This ensures that people trust how the questions are being graded.  If it’s just a black box, it is not an improvement on the capricious systems of patronage that it’s supposed to replace.  As evidence of this, during the Dà Míng dynasty, there was furor over the punctuation of graded exams.

So why am I, a computer science professor, talking all of this nonsense about history?  We use questions to test the intelligence of both humans and machines.  I talk about the Turing Test, the classic test of computer intelligence, and modern leaderboards in other videos, but in testing computer intelligence we shouldn’t forget about the lessons we’ve learned about human intelligence.

One of those lessons that I think that we’ve forgotten is that questions are not just an evaluation but also for instruction: in the lingo of artificial intelligence, they’re training data.  And because these training data build intelligence, they should be as high quality as possible so that the AI that results is as high quality as possible.

But even if you just take question answering as an evaluation for how smart an AI is, society should be able to trust those evaluations.  Just as the civil service exams made people trust their interactions with the government, as AI becomes more tightly integrated into our economy and our society, our vetting of AI will become more important.

Question answering is just one of many ways to secure trust, but it’s analogous to how to ensure lawyers, doctors, and pilots are qualified for their jobs.  So these tests should be unbiased, reliable, and the feedback from the tests should be transparent and understandable.

And we should do these things not just because we’re trying to make society work like a well-oiled machine or because we want to be confident in our estimates of statistics about artificial intelligence.  Just like Socrates, the questions we ask are trying to get to the truth, and scientific inquiry requires openness and a willingness to question the outcomes of a test.
