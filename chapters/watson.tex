

I remember when I first heard rumblings of Watson.
%
Because I had a foot in both the \abr{ai} and trivia communities, I
heard two different stories.
%
I heard rumors of a amazon work in parsing and semantic role labeling
happening from researchers who ventured north to Nassau county in New York (I was doing
my PhD at Princeton).
%
From the trivia community, I heard of some people who were being paid
by \abr{ibm} to play trivia games but that they couldn't say anything
more.

I was very sceptical.
%
By the time that Watson came to fruition, I had moved to the
University of Maryland.
%
Then, my scepticism turned to jealousy.
%
I watched, along with the rest of the world, one of the greatest
achievements of \abr{ai} unfold in front of me.
%
What was I doing wasting my time working on topic models if this was
also legitimate research?

Let me be clear that the technical triumphs are indisputable (and, in
my opinion, under-appreciated).
%
From the work on wagering to synthesizing multiple information
sources, Watson was from top to bottom a top-notch well-oiled machine.
%
And it computed all of this in real time---something that wasn't
strictly necessary but still impressive.

\section{This Game is Rigged, I Tell Ya!}

These successes have been well documented (not least by \abr{ibm} itself, who rightly celebrated the great achievements); however, things were not perfect\dots the game was rigged.  
%
It's useful to go over the lifecycle of an entire question: how it was
written, how it's communicated, how players answer, and how the score
is tabulated.
%
At every stage, there's a slight benefit to the computer, which taken
together makes this an unfair competition.

This is a problem!  First, it's a problem scientifically because we
want to have fair comparisons of human vs. computer intelligence.
%
More importantly, I want to have my turn having my question answering
robots face off against trivia whizzes (Chapter~\ref{ch:game-show}),
and I can't do that if everybody thinks that Watson's spin
on \jeopardy{} settled the question (and it hasn't).

% Cite / read this:
% https://dominoweb.draco.res.ibm.com/reports/rc25356.pdf

But first, in case you don't know how \jeopardy{} works, we'll review
that.
%
However, if you've calculated a Coryat score before, you can go ahead
and skip ahead.

\subsection{What \jeopardy{} is and How it Works}

\jeopardy{} is a gameshow created by Merv Griffin in 19XX.
%
Its big gimmick is that the player responses are given in the form of
a question.
%
For example, the clue ``The CAPTCHA test against spam \& robot programs
is called the `reverse' test named for this British code breaker''
would have response \answer{Who is Alan Turing}.
%
Nevertheless, we'll still sometimes call responses answers to be
consistent with the other chapters.
%
The clues are arranged in a grid: columns represent categories and
rows represent difficulty, with the more difficult questions being
worth more.

There are three players who stand side by side behind podiums.
%
When a clue is read, any of the three players can ``buzz in'' to say
that they want to give a response.
%
If they give the correct response, they then have ``control of the
board'' and can select the next clue.

One advantage of controlling the board is that some questions are
called ``Daily Doubles'' which allow the player to potentially double
their score: a player can wager any part of their score, and if they
get it right they get that ammount added to their score (but a wrong
response will subtract it from their score).

\subsection{The Pool of Questions}

Part of the agreement between \jeopardy{} and \abr{ibm} was that the
competition would take place on normal, written questions.
%
In the media coverage of the competition, this focused on avoiding
video and picture daily doubles (fairly reasonable, but we'll discuss
this more in a bit).
%
However, this causes two problems: the questions are too easy and do
not necessarily challenge computers.

So what makes up ``normal'' questions?
%
Every game of \jeopardy{} has questions that range in difficulty.
%
Because it's a television show, many questions are easy enough that
the average viewer at home can get them.
%
Moreover, the humans on the stage with Watson are not normal contestants.
%
Ken Jennings is certifiably the greatest of all time (\abr{goat}) \jeopardy{} player,
and Brad Rutter isn't bad himself.

The average ``normal'' \jeopardy{} contestant, including not so great
players like yours truly, know a large majority of the clues.
%
For top players like Brad and Ken, they know---with a handful of
exceptions--\emph{all} the clues.
%
In a one-on-one fight with normal clues, Ken and Brad would be
fighting every clue: it would come down to who could buzz first.

This isn't fun to play.
%
Nor is it fun to watch.
%
This is why \jeopardyp{}'s tournament of champions is played on much more difficult clues.
%
Nonetheless, this is the battlefield where Watson won: ``normal'' questions that didn't challenge the human players.
%
Instead, it all came down to the buzzer.

\subsection{John Henry vs. the Buzzing Machine}

Unlike \qb{} (Chapter~\ref{ch:qb}), while \jeopardy{} also uses
signaling devices, these only work \emph{once the question has been
read in its entirety}; Ken Jennings, one of the top \jeopardy{}
players (and also a former \qb{} player while he was a student at \abr{byu}) explains it on a \textit{Planet Money}
interview~\cite{malone-19}:
\begin{quote}
{\bf Jennings:} The buzzer is
    not live until Alex finishes reading the question. And if you buzz
    in before your buzzer goes live, \emph{you actually lock yourself out
    for a fraction of a second}. So the big mistake on the show is
    people who are all adrenalized and are buzzing too quickly, too
    eagerly. \\
{\bf Malone:} \abr{ok}. To some degree, \jeopardy{} is kind of a video game, and a \emph{crappy video game where it's, like, light goes on, press button}---that's it. \\
{\bf Jennings:} (Laughter) Yeah. \\
\end{quote}
\jeopardy{}'s buzzers are a gimmick to ensure good television; however, \qb{} buzzers discriminate knowledge.

So how does this interact with Watson?
%
Watson receives all of the clues electronically and likewise gets an electronic signal to know when it is safe to buzz in.
%
In contrast, humans have to either guess when it is safe to buzz or wait for a light to light up.

\jeopardy{} gurus explicitly advise new players not to wait for the light---your puny human reflexes are too slow.
%
Indeed, one of Ken Jenning's strengths was his uncanny ability to
internalize the cadence of Alex's voice and when a technitian would
activate the buzzer.
%
In contrast, Watson is literally an electromechanical buzzing machine
that could get first crack at every question it wants.\footnote{In
practice, this is not always true.  Because Watson computed its
responses in real time, it could not come up with a response in time
for particularly short questions.}

Moreover, what makes for a ``normal'' difficulty question for a human
does not always apply to a computer.
%
Let's first talk about what makes a clue easier for a computer and what makes a clue harder for a computer.

When I appeared on \jeopardyp{}, my final \jeopardy{} was:
%
\question{After this woman's death, her daughter wrote, ``As far as we in the family are concerned, the alphabet now ends at Y''}
%
All of us got the question right; it just so happened that \jeopardy{}
used a very similar clue that aired as we were recording:
%
\question{``G'' is for grand master as well as this woman who received the 2009 Grand Master Award.}
%
The correct response is of course \answer{Sue Grafton}.
%
For poorly read contestant like myself, only studying previous clues
allowed us to get the answer right.
%
I've never read a Grafton book, I know she writes mystery books and
has titles of the form \textit{``A'' is for Alibi} (and that's the
only title I can think without looking at Wikipedia).

For Watson, this is ``memorization'' is trivial: a single letter
implies that the answer is \underline{Grafton}.
%
But just like you should not think that I'm smart for getting lucky to
have seen a reused clue, you should not praise Watson for finding
near-repeat questions.
%
And it's not just trivia games: Google's dataset of questions have
many identical questions ().
%
Moreover, Watson can also store the entirety of Wikipedia, easily
looking up capitals, authors, etc.

Indeed, when a computer can find \emph{an exact quote} (as was in my final \jeopardy{} clue), the question becomes even easier.
%
Then the computer just needs to find the appropriate article that contains the quote and then just find whatever entity is mostly likely to be a \jeopardyp{} answer.

Where systems like Watson struggle are on computation, matching novels
and movies to plots, combining multiple clues, lateral thinking, and
wordplay.
%
And this is not just a matter of degree: computers struggle with all
such questions.
%
While a computer is theoretically good at math, the kinds of programs
that answer trivia questions struggle answering match questions with
numbers in the double digits.

This is why the goal of \abr{ai} is \emph{general} artificial
intelligence (Chapter~\ref{ch:turing}): while we can build specialized
systems for \jeopardy{} questions or math questions, unlike a
reasonably smart human, a single program can't ``do it all''.
%
Unlike for human contestants, the ``difficulty'' of \jeopardy{}
questions for a computer has no relationship to the nominal value.

And this is not a criticism of \jeopardy{} authors: how should they
know how a computer thinks?
%
Working with a brilliant undergraduate, Eric Wallace, we built an
interface to show professional trivia writers what a computer is
thinking so that they could appropriately calibrate trivia questions.

As authors type a question, they see the information the computer is
using to respond:
%
what Wikipedia articles it's using,
%
what previous clues it's looking at,
%
and what words in the clue it's using.
%
When professional trivia writers have access to this information, they can
avoid repeating themselves,
%
``Oh, thanks friendly popup, I didn't realize we just asked about
Grafton like that\dots I still want to ask about her, but let's mix
things up.''

My favorite example of how professional trivia writers used this information to trip up computers was this clue:
\begin{quote}
  The main character of a story by this author opens Crime and Punishment to a random page, but finds it to be a copy of The Brothers Karamazov, and equates himself with Monsieur Bovary.
\end{quote}
%
Now this is a hard clue (worthly of a competition between Ken and Brad), and you may not know the answer; there's no shame in that.

But if you're relatively well-read, you probably know that the answer is {\bf not} Fyodor Dostoevsky, the author of \textit{Crime and Punishment}.
%
How do you know that?  
%
First, Dostoyevski isn't really a self-referential author, so he wouldn't write about his own novels\dots also, \textit{The Brothers Karamazov} was is last major work, so in what story could this happen?
%
But while a computer technically ``knows'' all of this information, it isn't going to use this to answer the question.

Instead, it sees the phrase ``this author opens Crime and Punishment'' and can see that a dozen other questions have used this exact phrase, it thus buzzes in confidently that the answer is \answer{Fyodor Dostoevsky}.
%
Indeed, you don't need to be a Dostoevsky expert to stay away from that\dots you just need to understand a little linguistics.
%
The verb ``opens'' has the subject ``the main character'' \emph{not} ``this author''.
%
However, the computer greedily focuses on what it's seen before.

Again, this is not a criticism of the \jeopardy{} writers nor of the \abr{ibm} folks who set up the competition.
%
These nuances are only obvious after the fact (and some of my early human--computer competitions had similar shortcomings), but I hope that it can help shape our future understanding of machine intelligence.  
%
We will talk about what happens when you set up a fair competition between
humans and computers on these types of questions in
Chapter~\ref{ch:leaderboard}.

\subsection{Two Nice Guys, One Computer with no Shame}

Given the ``too easy'' questions and the buzzer, what does this actually mean for gameplay?  
%
A question comes in, and Watson has the choice of answering it or not: it can win every race to the buzzer if it wants.
%
Then, of the things it cannot answer, Ken and Brad fight over the scraps.
%
Thus, for a computer to win this competition, it needs only to be able to answer a third of the questions correctly.

Now, the \jeopardy{} nerds reading the book (I love you all), will point out that this isn't true, because the clues are not weighted equally: some are worth more than others.
%
However, as we discussed above, what's difficult for a computer isn't always difficult for a human (and \textit{vice versa}), so it really is a random third of the questions.
%
While a good human player might be weak on the buzzer and be confident that if they know more they'll win the harder clues, this isn't true for a human facing off against Watson.

Moreover, the computer has no shame: it uses a strategy called the ``Forrest Bounce'' (more infamously associated with James Holzhauer and Arthur Chu).
%
Rather than going through the categories top to bottom (easy to hard), Watson goes through the clues somewhat randomly, searching for Daily Doubles and trying to optimize its score.
%
Again, there's nothing wrong with this---it's the optimal strategy!
%
But if it's the ``right'' way to play the game, why doesn't every human do it?

That's because humans want to follow social norms.
%
The producers of the show (hi, Maggie and Corinna!) tell you up and down that you shouldn't play the game like that, and you don't want to make them unhappy with you\dots they can make your life miserable.
%
I remember watching \jeopardy{} with my grandmother and when someone hunted for the Daily Double, she would always say ``who does he think he is'' (and it was always a he).
%
Alex Trebek also wasn't a fan:
%
\begin{quote}
When the show's writers construct categories they do it so that there's a flow in terms of difficulty, and if you jump to the bottom of the category you may get a clue that would be easier to understand if you'd begun at the top of the category and saw how the clues worked. I like there to be order on the show, but as the impartial host I accept disorder.
\end{quote}
%
And nobody, nobody, wants to make Alex unhappy.

Ken would sometimes do a little hunding for the Daily Double against a particularly formiddable opponent, but he would normally be well-behavied so as not to upset the powers that be.
%
Watson, however, was a soulless machine; the novelty was such that nobody faulted it for its strategy.
%
If anyone is to blame, it's probably Gary Tessauro; adding his strategy for playing the board increased Watson's win percentage considerably.
%
Put him in a room with the \jeopardy{} producers and that code would be commented out in no time.

\subsection{Written, not Spoken}

The 

\section{The Legacy of Watson}

Let's review Watson's appearance on \jeopardyp{}:
\begin{enumerate*}
        \item all questions are of ``normal'' difficulty;
        \item thus the two human contestants know nearly all of the clues; but
        \item Watson can win the buzzer race whenever it wants.
\end{enumerate*}
If Watson wins such a match, does that mean that it is superior to
these supurb humans?