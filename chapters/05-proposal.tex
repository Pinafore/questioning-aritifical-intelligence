
\paragraph{Proposed Title and Subtitle} \vspace{3cm}

{\bf Questioning Artificial Intelligence}: What the Differences between how
Computers and Humans Answer Questions reveal about Intelligence and an
AI-dominated Future.

\vspace{3cm}

Humans have been answering questions for millenia: \OE{}dipus answering the
Sphynx's riddles, civil servants proving their worth on exams, and contestants
on \jeopardyp{}.
%
But now computers are doing the same thing: answering idle questions on smart
devices, competing on game shows, and threatening to take our jobs.
%
This book looks at how---despite the superficial similarity in the end
result---dramatically different the underlying mechanisms for human and
computer question answering are and what that says about the future of
human--computer coexistance.

\paragraph{Full Description}

We call someone smart if they can answer questions: the pass a test, win
on \jeopardyp{}, or offer a witty retort in a debate.
%
This is not just a recent phenomenon: question answering is deeply embedded in
our culture.
%
In myth \OE{}dipus answered the riddle of the sphynx.
%
Good governance depends on civil service exams.
%
A trivia subculture has grown around answering all manner of questions.

What is new is that computers are now getting into the game of answering
questions.
%
From \abr{ibm} Watson on \jeopardy{} to Siri in every home, the ability of
computers to answer is a common yardstick of how smart computers are.

This book is not a book about how to build \abr{ai} systems or how use natural
language processing to extract answers from Wikipedia.
%
There are plenty of tutorials that teach you how to do that.
%
Nor is it an insider's guide to the world of high-stakes educational testing,
trivia games, or licensing exams.

Unlike those books, the goal of this book is to draw \emph{connections}
between these two worlds of human and computer question answering.
%
The length of time computers have been answering questions well is shorter
than the tenure of beloved game show hosts.
%
However, the \abr{ai} boffins building these impressive systems have ignored
the hard-won lessons of humans' centuries of practice.

My argument is that we can better understand artificial intelligence by
looking at its ability to answer questions through this historical lens.
%
If we want to call a computer smart---indeed, smarter than a human---we should
make sure the competition is fair.
%
Moreover, writing and asking questions is an art that has been refined over
decades.

But the artificial intelligence community has not done this because of a
decision made at a British university fifty years ago.
%
As a consequence, we are stuck with the crappy answers from our smartphone.

But it didn't have to be this way!
%
The very definition of computing and artificial intelligence was based a
thought experiment that is closer to how computers and humans should interact
with each other.
%
However, that definition was too fanciful to really be implemented in the lab.

After reviewing the history of question answering of both humans and
computers, this book argues for rethinking how we ask questions and evaluates
answers.
%
This is not just a narrow question for those building question answering.
%
I'll argue that it will define the future of human--computer interaction and
thus the shape of the modern, \abr{ai}-infused economy.


\paragraph{Proposed Chapter Outline}

Proposed table of contentents follows.

\begin{enumerate}
        \item Question Answering Past

        \begin{enumerate*}
                \item {\bf Epic Questions}: Questions have been with us for
                millenia.  One reason is that they're entertaining.  But it's
                more than that: the ability to ask and answer questions is
                close to godliness.  Through the lens of the Riddle of the
                Sphynx and Gestumblindi, this chapter examines what makes a
                good question in the eyes of the Gods.

                \item {\bf The Foundation of Civilization}: Civil service
                exams broke the corruption and randomness of patronage and
                familial bonds.  By examining the reforms of Wu Zetian and the
                Pendelton Act, this chapter examines how information and
                competence---measured by questions asked in an exam---created
                meritocracy and social mobility.

        \end{enumerate*}

        \item Question Answering Present

        \begin{enumerate*}

        \item {\bf The Turing Test}: Alan Turing's eponymous Turing Test is
        the most durable (but contentious) definition of what it means for a
        computer to be intelligent.  This chapter reviews how Alan Turing's
        postwar thought experiment shaped the development of artificial
        intelligence.

        \item {\bf Trivia Snobs}: Just as Alan Turing's wartime exploits
        shaped \abr{ai}, this chapter charts the course of how a Canadian
        soldier created a revolution in how humans play trivia games (but
        these insights are ignored by the computer community).

        \item {\bf What Makes a Good Question}:\footnote{Published as a
        position piece at the Association of Computational Linguistics 2020.}
        Contrasting with the previous chapter, this chapter describes the best
        practices of human question answering---non-ambiguous, discriminative,
        and fair---and how these best practices grew out of decades of
        refinement.

        \item {\bf IBM Watson on \jeopardyp{}: Simultaneously a \textit{tour de
        force} and a sham}: The most memorable computer to answer questions
        caused the public to think that question answering had been
        ``solved'', but that's not true.  This chapter breaks down why despite
        the hype and victory Watson's victory doesn't tell us that much about
        how well computers can answer questions.

        \item {\bf Question Answering Datasets and Methods}:
        This chapter reviews how computers answer questions: learning from
        example datasets and then recreate those examples from those datasets.
        This chapter critically examines how computers answer questions and
        how this can make computers seem smarter than they are.
        
        \item {\bf Cranfield vs. Manchester}:\footnote{Submitted as a short
        position piece to Empirical Methods in Natural Language Processing
        2021.} At a 1960s meeting in Cranfield, the computer science community
        embarked on a paradigm that downplayed the user of experts in defining
        systems.  This legacy, a shift from Alan Turing, still defines
        question answering today.

        \item {\bf Leaderboards and Tournaments}: Computers compete on
        leaderboards, while humans compete at tournaments.  The latter has
        been optimized over decades to efficiently select the best human
        competitor, while leaderboards have not taken advantage of the tips
        and tricks that make tournaments for humans fun and informative.

        \end{enumerate*}

        \item Question Answering Future

        \begin{enumerate*}
        \item {\bf Science Fiction Question Answering}: Science fiction is the
        standard mode of predicting how humans and computers will interact in
        the future.  From Hal's questions in \textit{2001} to the Voigt-Kampff
        test in \textit{Blade Runner}, this chapter reflects on how plausible
        and what warnings science fiction offers for question answering.

        \item {\bf Human--Computer Centaurs}: This chapter looks at
        another \abr{ai} victory---chess---and how computers evolved into
        collaborators of humans rather than competitors.  How should computers
        and humans work together to answer hard questions?  The answer (and
        how we build \abr{ai} systems) will determine the future of the
        economy.

        \item {\bf Computer Game Shows of the Future}: Finally, we bring
        together two of the themes of the book: computers answering questions
        and game shows.  How could we use the gimick of the game show format
        to shape \abr{ai} into what would best serve society and help inform the
        public about the true state of \abr{ai} research.

        \end{enumerate*}

\end{enumerate}

\paragraph{Author Information}

Jordan Boyd-Graber is an associate professor at the University of Maryland.
He recieved a PhD from Princeton in 2010 in Computer Science and a bachelor's
degree in History from the California Institute of Technology.
%
His work has been recognized with ``best of'' awards at Intelligent User
Interfaces, Neural Information Processing Systems, the North American
Association for Computational Linguistics, and the Conference on Natural
Language Learning.
%
He also recieved a National Science Foundation \abr{career} award and the 2015
Karen Sp\"ark Jones Award.
%
He has published over a hundred peer-reviewed publications on interactive
machine learning, question answering, and exploring document collections.
%
With David Mimno and Yuening Hu, he wrote \emph{Applications of Topic Models}.

In addition to his academic research, Boyd-Graber is also active in the trivia
community: he founded the University of Colorado Quiz Bowl team, revived the
Princeton Graduate College Pub Quiz, coaches the national champion University
of Maryland Academic Quiz Team, and has lost on \jeopardyp{}: his
students are particularly fond of mocking his poor performance on the
video game category.

\paragraph{Book Audience}

The book is intended either for the general public to learn about humand and computer
question answering or for machine learning researchers to learn
how \emph{human} question answering can improve their computer question
answering systems.

\paragraph{Comparable Books}

\begin{itemize}
        \item Ken Jennings.  \textit{Braniac: Adventures in the Curious,
        Competitive, Compulsive World of Trivia Buffs}.  Villard, 2007.

        \item Mark T. Maybury.  \textit{New Directions in Question
        Answering}.  AAAI Press, 2004.

        \item Navin Sabharwal and Amit Agrawal.  \textit{Hands-on Question
        Answering Systems with BERT}.  A Press, 2021.
\end{itemize}


\paragraph{Additional Information and Specifications}

Estimated book contents:
\begin{itemize}
  \item 250 Double-spaced pages
  \item Two dozen diagrams / illustrations
  \item Draft to reviewers August 31, 2021, revisions/edits until
    January 31, 2021
\end{itemize}

Two chapters were submitted to conferences as position papers (one
accepted, one under review).  If accepted, the chapters will be
substantially revised to flow well with and complement other
chapters.  The following sample chapter is an adaptation of the 2020 \abr{acl}
paper, substantially rewritten in a more conversational style for a
book audience.
