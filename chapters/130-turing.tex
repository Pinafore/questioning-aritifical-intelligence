
The history of artificial intelligence begins in many ways with a question answering game.  This idea came out of the research of a researcher at the University of Manchester named Alan Turing.  

He’s probably better known for being one of the scientists who decoded the Nazi Enigma device (which is why his memorial bench has ciphertext underneath his name) and helped bring World War II in Europe to an earlier conclusion.

But Turing is also a game designer.  Quoting from Bishop’s description:
\begin{quote}
Turing called for a human interrogator (C) to hold a conversation with a male and female respondent (A and B) with whom the interrogator could communicate only indirectly by typewritten text. The object of this game was for the interrogator to correctly identify the gender of the players (A and B) purely as a result of such textual interactions
\end{quote}

The players can lie, so the key to correctly deciding the genders of the players is more about determining which player lacks key knowledge about the experience of being a man or a woman.\footnote{What makes the Turing Test more poignant to me, at least, is that as a closeted gay man in a country where homosexuality is illegal, every interaction is dangerous: Turing is pretending to be something that he is not, and has to present himself as if he were a heterosexual man.  There's no evidence evidence to suggest that this was an inspiration for his first Turing Test, however.}

But what does this have to do with \abr{ai}?  Turing then thought, let’s replace the man and the woman with a computer and a human.  If the interrogator cannot determine which is the computer and which is the machine, then the machine has displayed something that looks like intelligence.

But I want to emphasize not just the broad strokes of the Turing Test, but why we need to think critically about things that call themselves the Turing test.  Also, it’s more fun than talking abstractly about the Turing test.

Let’s start with \abr{parry}, a system designed by Kenneth Mark Colby to simulate a paranoid schizophrenic.  And when you connected psychiatrists to either real patients or \abr{parry}, they couldn’t tell the difference.  So here the problem is the judges.  Not because they aren’t experts--they are--but because their backgrounds prevent them from being effective judges.

Psychiatrists are doctors bound by the hippocratic oath: they cannot ask probing, in-depth questions that might harm a patient.  So, thus, this really isn’t a Turing test.

Stu Schieber has a great take on this problem; I’d encourage you to read the whole thing.  His take is on a competition called the Loebner prize that purports to implement the Turing Test.  But here, the interrogators are limited in the topics they can ask about.  So again, competitions that don’t have skilled interrogators allowed to ask any question they which.

Another example that some people claim is an example of AI passing the Turing Test is Google Duplex: Google offers to call a restaurant to make a reservation for you.  Their text-to-speech system is very good, but also puts in dysfluencies such as adding ``um'' and pauses to make it sound more human.  Here, the judge is fooled into thinking that they’re talking to a human.  But this doesn’t count either because the judge doesn’t know they’re a judge!  The poor employee on the other end of the phone call is expecting a human until proven wrong.

All of this doesn’t mean that the Turing Test is flawed.  It has remained a part of AI for three quarters of a century because it’s a simple, intuitive test of whether we have achieved artificial intelligence.  So although we haven’t had a real Turing Test yet, a judge asking questions of either an \abr{ai} or a human remains many researchers’ goal.

So let’s be true to the spirit of Turing’s idea of a parlor game.  Let’s make it visible to the public, let’s refine the rules and the judges to make it more realistic and more fun.  By putting these games in the public view and letting judges learn the best strategies for discerning humans from computers, both sides can become worthier adversaries.  

And I think putting this slow advance of ever more capable computers answering trickier questions should be out in front of the public.  Not just to keep the interrogators honest but to also keep the companies and interests that sell AI honest.  The public has a vested interest in knowing the limits of AI, and this is a fine way to make that public.  But on the other side of the coin, it is also worthwhile for the public to know when AI has really advanced… the public has a right to know how computers react to challenging scenarios.  Better to see them first played out for fun in a game than in high-stakes transactions, a doctor’s office, or a courtroom.

But above all, this only works if we have good questions, so if we believe that the Turing test really is the holy grail of AI, we as humans need to know how to ask the right questions and computers need to be able to answer any question that’s thrown at them.

\section{General Artificial Intelligence}
\label{sec:turing:gai}
